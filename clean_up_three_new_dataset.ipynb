{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "______________\n",
    "DAMI2 Project Report Code - Handling unbalanced datasets\n",
    "\n",
    "2020 Jimmy Ljungman\n",
    "\n",
    "This code imports a data set, preprocesses it, run a new sampling technique\n",
    "called 'Unbalanced_bagging' and measure its performance against other sampling techniques\n",
    "such as random oversampling and random undersampling.\n",
    "\n",
    "Unbalanced_bagging will be measured against the other techniques using the metrics AUPRC and time complexity."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "______________\n",
    "Importing necessary libraries and setting global variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import average_precision_score\n",
    "import random\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "\n",
    "RANDOM_SEED = 12345"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(\"datasets/diabetes.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "data": {
      "text/plain": "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  768.000000     768.000000     768.000000  768.000000   \nmean      3.845052  120.894531      69.105469      20.536458   79.799479   \nstd       3.369578   31.972618      19.355807      15.952218  115.244002   \nmin       0.000000    0.000000       0.000000       0.000000    0.000000   \n25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n75%       6.000000  140.250000      80.000000      32.000000  127.250000   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age     Outcome  \ncount  768.000000                768.000000  768.000000  768.000000  \nmean    31.992578                  0.471876   33.240885    0.348958  \nstd      7.884160                  0.331329   11.760232    0.476951  \nmin      0.000000                  0.078000   21.000000    0.000000  \n25%     27.300000                  0.243750   24.000000    0.000000  \n50%     32.000000                  0.372500   29.000000    0.000000  \n75%     36.600000                  0.626250   41.000000    1.000000  \nmax     67.100000                  2.420000   81.000000    1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.845052</td>\n      <td>120.894531</td>\n      <td>69.105469</td>\n      <td>20.536458</td>\n      <td>79.799479</td>\n      <td>31.992578</td>\n      <td>0.471876</td>\n      <td>33.240885</td>\n      <td>0.348958</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.369578</td>\n      <td>31.972618</td>\n      <td>19.355807</td>\n      <td>15.952218</td>\n      <td>115.244002</td>\n      <td>7.884160</td>\n      <td>0.331329</td>\n      <td>11.760232</td>\n      <td>0.476951</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.078000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>99.000000</td>\n      <td>62.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>27.300000</td>\n      <td>0.243750</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>117.000000</td>\n      <td>72.000000</td>\n      <td>23.000000</td>\n      <td>30.500000</td>\n      <td>32.000000</td>\n      <td>0.372500</td>\n      <td>29.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.000000</td>\n      <td>140.250000</td>\n      <td>80.000000</td>\n      <td>32.000000</td>\n      <td>127.250000</td>\n      <td>36.600000</td>\n      <td>0.626250</td>\n      <td>41.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>17.000000</td>\n      <td>199.000000</td>\n      <td>122.000000</td>\n      <td>99.000000</td>\n      <td>846.000000</td>\n      <td>67.100000</td>\n      <td>2.420000</td>\n      <td>81.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.describe()\n",
    "#weird that \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\" have zero values, imputate mean values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "def imputation(data, columns):\n",
    "    for c in columns:\n",
    "         if c in data.columns:\n",
    "             data[c].replace(0, np.nan,inplace=True)\n",
    "             data[c].fillna(data[c].mean(), inplace=True)\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "data": {
      "text/plain": "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  768.000000     768.000000     768.000000  768.000000   \nmean      3.845052  121.686763      72.405184      29.153420  155.548223   \nstd       3.369578   30.435949      12.096346       8.790942   85.021108   \nmin       0.000000   44.000000      24.000000       7.000000   14.000000   \n25%       1.000000   99.750000      64.000000      25.000000  121.500000   \n50%       3.000000  117.000000      72.202592      29.153420  155.548223   \n75%       6.000000  140.250000      80.000000      32.000000  155.548223   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age     Outcome  \ncount  768.000000                768.000000  768.000000  768.000000  \nmean    32.457464                  0.471876   33.240885    0.348958  \nstd      6.875151                  0.331329   11.760232    0.476951  \nmin     18.200000                  0.078000   21.000000    0.000000  \n25%     27.500000                  0.243750   24.000000    0.000000  \n50%     32.400000                  0.372500   29.000000    0.000000  \n75%     36.600000                  0.626250   41.000000    1.000000  \nmax     67.100000                  2.420000   81.000000    1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.845052</td>\n      <td>121.686763</td>\n      <td>72.405184</td>\n      <td>29.153420</td>\n      <td>155.548223</td>\n      <td>32.457464</td>\n      <td>0.471876</td>\n      <td>33.240885</td>\n      <td>0.348958</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.369578</td>\n      <td>30.435949</td>\n      <td>12.096346</td>\n      <td>8.790942</td>\n      <td>85.021108</td>\n      <td>6.875151</td>\n      <td>0.331329</td>\n      <td>11.760232</td>\n      <td>0.476951</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>44.000000</td>\n      <td>24.000000</td>\n      <td>7.000000</td>\n      <td>14.000000</td>\n      <td>18.200000</td>\n      <td>0.078000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>99.750000</td>\n      <td>64.000000</td>\n      <td>25.000000</td>\n      <td>121.500000</td>\n      <td>27.500000</td>\n      <td>0.243750</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>117.000000</td>\n      <td>72.202592</td>\n      <td>29.153420</td>\n      <td>155.548223</td>\n      <td>32.400000</td>\n      <td>0.372500</td>\n      <td>29.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.000000</td>\n      <td>140.250000</td>\n      <td>80.000000</td>\n      <td>32.000000</td>\n      <td>155.548223</td>\n      <td>36.600000</td>\n      <td>0.626250</td>\n      <td>41.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>17.000000</td>\n      <td>199.000000</td>\n      <td>122.000000</td>\n      <td>99.000000</td>\n      <td>846.000000</td>\n      <td>67.100000</td>\n      <td>2.420000</td>\n      <td>81.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = imputation(original_df, [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"])\n",
    "\n",
    "original_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:title={'center':'Plot over class imbalance'}>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_labels = original_df.Outcome.value_counts()\n",
    "total_labels.plot(kind='bar', title='Plot over class imbalance')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "data": {
      "text/plain": "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  768.000000     768.000000     768.000000  768.000000   \nmean      3.845052  121.686763      72.405184      29.153420  155.548223   \nstd       3.369578   30.435949      12.096346       8.790942   85.021108   \nmin       0.000000   44.000000      24.000000       7.000000   14.000000   \n25%       1.000000   99.750000      64.000000      25.000000  121.500000   \n50%       3.000000  117.000000      72.202592      29.153420  155.548223   \n75%       6.000000  140.250000      80.000000      32.000000  155.548223   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age  \ncount  768.000000                768.000000  768.000000  \nmean    32.457464                  0.471876   33.240885  \nstd      6.875151                  0.331329   11.760232  \nmin     18.200000                  0.078000   21.000000  \n25%     27.500000                  0.243750   24.000000  \n50%     32.400000                  0.372500   29.000000  \n75%     36.600000                  0.626250   41.000000  \nmax     67.100000                  2.420000   81.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.845052</td>\n      <td>121.686763</td>\n      <td>72.405184</td>\n      <td>29.153420</td>\n      <td>155.548223</td>\n      <td>32.457464</td>\n      <td>0.471876</td>\n      <td>33.240885</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.369578</td>\n      <td>30.435949</td>\n      <td>12.096346</td>\n      <td>8.790942</td>\n      <td>85.021108</td>\n      <td>6.875151</td>\n      <td>0.331329</td>\n      <td>11.760232</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>44.000000</td>\n      <td>24.000000</td>\n      <td>7.000000</td>\n      <td>14.000000</td>\n      <td>18.200000</td>\n      <td>0.078000</td>\n      <td>21.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>99.750000</td>\n      <td>64.000000</td>\n      <td>25.000000</td>\n      <td>121.500000</td>\n      <td>27.500000</td>\n      <td>0.243750</td>\n      <td>24.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>117.000000</td>\n      <td>72.202592</td>\n      <td>29.153420</td>\n      <td>155.548223</td>\n      <td>32.400000</td>\n      <td>0.372500</td>\n      <td>29.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.000000</td>\n      <td>140.250000</td>\n      <td>80.000000</td>\n      <td>32.000000</td>\n      <td>155.548223</td>\n      <td>36.600000</td>\n      <td>0.626250</td>\n      <td>41.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>17.000000</td>\n      <td>199.000000</td>\n      <td>122.000000</td>\n      <td>99.000000</td>\n      <td>846.000000</td>\n      <td>67.100000</td>\n      <td>2.420000</td>\n      <td>81.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can now split attributes and class label\n",
    "X = original_df.drop('Outcome', axis=1)\n",
    "y = original_df.Outcome\n",
    "\n",
    "X.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "def unbalanced_bagger(x, y, M = 1, sampling_techniques = None, base_estimator = None):\n",
    "    if sampling_techniques is None:\n",
    "        sampling_techniques = []\n",
    "    if base_estimator is None:\n",
    "        base_estimator = DecisionTreeClassifier()\n",
    "\n",
    "    base_learners = []\n",
    "    for i in range(M):\n",
    "\n",
    "        rnd = np.random.choice(x.shape[0], size=x.shape[0])\n",
    "        x_bootstrap = x.iloc[rnd,:]\n",
    "        y_bootstrap = y.iloc[rnd]\n",
    "\n",
    "        technique = random.randint(0,len(sampling_techniques)-1)\n",
    "        x_sample, y_sample = sampling_techniques[technique].fit_sample(x_bootstrap,y_bootstrap)\n",
    "\n",
    "        base_estimator.fit(x_sample,y_sample)\n",
    "        base_learners.append(base_estimator)\n",
    "\n",
    "    def predict(x):\n",
    "        predictions = np.zeros([x.shape[0], len(base_learners)])\n",
    "        for i in range(len(base_learners)):\n",
    "            predictions[:,i] = base_learners[i].predict(x)\n",
    "        return mode(predictions, axis=1)[0]\n",
    "    return predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unbalanced_bagger_two(x, y, M = 1, sampling_techniques = None, base_estimator = None):\n",
    "    if sampling_techniques is None:\n",
    "        sampling_techniques = []\n",
    "    if base_estimator is None:\n",
    "        base_estimator = DecisionTreeClassifier()\n",
    "\n",
    "    base_learners = []\n",
    "    for i in range(M):\n",
    "\n",
    "        rnd = np.random.choice(x.shape[0], size=x.shape[0])\n",
    "        x_bootstrap = x.iloc[rnd,:]\n",
    "        y_bootstrap = y.iloc[rnd]\n",
    "\n",
    "        technique = random.randint(0,len(sampling_techniques)-1)\n",
    "        x_sample, y_sample = sampling_techniques[technique].fit_sample(x_bootstrap,y_bootstrap)\n",
    "\n",
    "        base_estimator.fit(x_sample,y_sample)\n",
    "        base_learners.append(base_estimator)\n",
    "\n",
    "    def predict(x):\n",
    "        predictions = np.zeros([x.shape[0], len(base_learners)])\n",
    "        for i in range(len(base_learners)):\n",
    "            predictions[:,i] = base_learners[i].predict(x)\n",
    "        return mode(predictions, axis=1)[0],1\n",
    "\n",
    "    return predict\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [],
   "source": [
    "def unbalanced_bagger_no_sampling(x, y, M = 1):\n",
    "    #M = Amount of base_learners, x = train set, y = class labels\n",
    "    base_learners = []\n",
    "    for i in range(M):\n",
    "        #boostrap replica\n",
    "        rnd = np.random.choice(x.shape[0], size=x.shape[0])\n",
    "        x_bootstrap = x.iloc[rnd,:]\n",
    "        y_bootstrap = y.iloc[rnd]\n",
    "        #train\n",
    "        clf = DecisionTreeClassifier()\n",
    "        clf.fit(x_bootstrap,y_bootstrap)\n",
    "        base_learners.append(clf)\n",
    "\n",
    "    def predict(x):\n",
    "        predictions = np.zeros([x.shape[0], len(base_learners)])\n",
    "        for i in range(len(base_learners)):\n",
    "            predictions[:,i] = base_learners[i].predict(x)\n",
    "        return mode(predictions, axis=1)[0]\n",
    "    return predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [],
   "source": [
    "X_training,X_testing,y_training,y_testing, = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED)\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_training, y_training, test_size=0.3, random_state=RANDOM_SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=RANDOM_SEED)\n",
    "rus = RandomUnderSampler(random_state=RANDOM_SEED)\n",
    "smote = SMOTE(random_state=RANDOM_SEED, sampling_strategy='minority')\n",
    "\n",
    "sampling_techniques = [ros, rus,smote]\n",
    "classifier = unbalanced_bagger(x_train, y_train, 10, sampling_techniques)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data balanced by Unbalanced Bagger (1)\n",
      "\n",
      "Validation Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       102\n",
      "           1       0.54      0.48      0.51        60\n",
      "\n",
      "    accuracy                           0.65       162\n",
      "   macro avg       0.62      0.62      0.62       162\n",
      "weighted avg       0.65      0.65      0.65       162\n",
      "\n",
      "\n",
      "Test Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       158\n",
      "           1       0.62      0.62      0.62        73\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.72      0.72      0.72       231\n",
      "weighted avg       0.76      0.76      0.76       231\n",
      "\n",
      "Average precision-recall score: 0.50\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "function should be a binary classifier",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-118-a27e326c4749>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     11\u001B[0m       average_precision))\n\u001B[0;32m     12\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 13\u001B[1;33m \u001B[0mdisp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mplot_precision_recall_curve\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassifier\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_testing\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_testing\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     14\u001B[0m disp.ax_.set_title('2-class Precision-Recall curve: '\n\u001B[0;32m     15\u001B[0m                    'AP={0:0.2f}'.format(average_precision))\n",
      "\u001B[1;32mc:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001B[0m in \u001B[0;36minner_f\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     70\u001B[0m                           FutureWarning)\n\u001B[0;32m     71\u001B[0m         \u001B[0mkwargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m{\u001B[0m\u001B[0mk\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mk\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msig\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0minner_f\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\ljung\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\metrics\\_plot\\precision_recall_curve.py\u001B[0m in \u001B[0;36mplot_precision_recall_curve\u001B[1;34m(estimator, X, y, sample_weight, response_method, name, ax, **kwargs)\u001B[0m\n\u001B[0;32m    155\u001B[0m         estimator.__class__.__name__))\n\u001B[0;32m    156\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mis_classifier\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 157\u001B[1;33m         \u001B[1;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclassification_error\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    159\u001B[0m     prediction_method = _check_classifer_response_method(estimator,\n",
      "\u001B[1;31mValueError\u001B[0m: function should be a binary classifier"
     ]
    }
   ],
   "source": [
    "y_score = classifier(X_testing)\n",
    "\n",
    "print(\"Data balanced by Unbalanced Bagger (1)\")\n",
    "print(\"\\nValidation Results:\")\n",
    "print(classification_report(y_val, classifier(x_val)))\n",
    "print(\"\\nTest Results:\")\n",
    "print(classification_report(y_testing, y_score))\n",
    "\n",
    "#true_labels, predicted_probs\n",
    "average_precision = average_precision_score(y_testing, y_score)\n",
    "print('Average precision-recall score: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "disp = plot_precision_recall_curve(classifier, X_testing, y_testing)\n",
    "disp.ax_.set_title('2-class Precision-Recall curve: '\n",
    "                   'AP={0:0.2f}'.format(average_precision))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sampling_techniques = [rus]\n",
    "classifier = unbalanced_bagger(x_train, y_train, 10, sampling_techniques)\n",
    "\n",
    "print(\"Data balanced by Unbalanced Bagger (2)\")\n",
    "print(\"\\nValidation Results:\")\n",
    "print(classification_report(y_val, classifier(x_val)))\n",
    "print(\"\\nTest Results:\")\n",
    "print(classification_report(y_testing, classifier(X_testing)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = unbalanced_bagger_no_sampling(x_train, y_train, 10)\n",
    "print(\"unbalanced_bagger_no_sampling(1)\")\n",
    "print(\"\\nValidation Results:\")\n",
    "print(classification_report(y_val, classifier(x_val)))\n",
    "print(\"\\nTest Results:\")\n",
    "print(classification_report(y_testing, classifier(X_testing)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "\n",
    "def unbalanced_dataset_technique():\n",
    "    clf.fit(x_train, y_train)\n",
    "    return clf\n",
    "\n",
    "def smote_technique():\n",
    "    smote = SMOTE(random_state=RANDOM_SEED,sampling_strategy='minority')\n",
    "    x_sample, y_sample = smote.fit_sample(x_train, y_train)\n",
    "    clf.fit(x_sample,y_sample)\n",
    "    return clf\n",
    "\n",
    "def random_oversampling_technique():\n",
    "    ros = RandomOverSampler(random_state=RANDOM_SEED)\n",
    "    x_sample, y_sample = ros.fit_sample(x_train, y_train)\n",
    "    clf.fit(x_sample, y_sample)\n",
    "    return clf\n",
    "\n",
    "def random_undersampling_technique():\n",
    "    rus = RandomUnderSampler(random_state=RANDOM_SEED)\n",
    "    x_sample, y_sample = rus.fit_sample(x_train, y_train)\n",
    "    clf.fit(x_sample, y_sample)\n",
    "    return clf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Train on original data\n",
    "print(\"Original data\")\n",
    "classifier = unbalanced_dataset_technique()\n",
    "print(\"\\nValidation Results:\")\n",
    "print(classification_report(y_val, classifier.predict(x_val)))\n",
    "print(\"\\nTest Results:\")\n",
    "print(classification_report(y_testing, classifier.predict(X_testing)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Train on SMOTE\n",
    "print(\"Data balanced by SMOTE\")\n",
    "classifier = smote_technique()\n",
    "print(\"\\nValidation Results:\")\n",
    "print(classification_report(y_val, classifier.predict(x_val)))\n",
    "print(\"\\nTest Results:\")\n",
    "print(classification_report(y_testing, classifier.predict(X_testing)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Train on Random Oversampling\n",
    "print(\"Data balanced by Random Oversampling\")\n",
    "classifier = random_oversampling_technique()\n",
    "print(\"\\nValidation Results:\")\n",
    "print(classification_report(y_val, classifier.predict(x_val)))\n",
    "print(\"\\nTest Results:\")\n",
    "print(classification_report(y_testing, classifier.predict(X_testing)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Train on Random Undersampling\n",
    "print(\"Data balanced by Random Undersampling\")\n",
    "classifier = random_undersampling_technique()\n",
    "print(\"\\nValidation Results:\")\n",
    "print(classification_report(y_val, classifier.predict(x_val)))\n",
    "print(\"\\nTest Results:\")\n",
    "print(classification_report(y_testing, classifier.predict(X_testing)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}