{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "______________\n",
    "Importing necessary libraries and setting global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import average_precision_score\n",
    "import random\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from models import UnbalancedBagger, UnbalancedBaggerNoSampling\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "RANDOM_SEED = 12345"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(\"datasets/diabetes.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  768.000000     768.000000     768.000000  768.000000   \nmean      3.845052  120.894531      69.105469      20.536458   79.799479   \nstd       3.369578   31.972618      19.355807      15.952218  115.244002   \nmin       0.000000    0.000000       0.000000       0.000000    0.000000   \n25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n75%       6.000000  140.250000      80.000000      32.000000  127.250000   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age     Outcome  \ncount  768.000000                768.000000  768.000000  768.000000  \nmean    31.992578                  0.471876   33.240885    0.348958  \nstd      7.884160                  0.331329   11.760232    0.476951  \nmin      0.000000                  0.078000   21.000000    0.000000  \n25%     27.300000                  0.243750   24.000000    0.000000  \n50%     32.000000                  0.372500   29.000000    0.000000  \n75%     36.600000                  0.626250   41.000000    1.000000  \nmax     67.100000                  2.420000   81.000000    1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.845052</td>\n      <td>120.894531</td>\n      <td>69.105469</td>\n      <td>20.536458</td>\n      <td>79.799479</td>\n      <td>31.992578</td>\n      <td>0.471876</td>\n      <td>33.240885</td>\n      <td>0.348958</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.369578</td>\n      <td>31.972618</td>\n      <td>19.355807</td>\n      <td>15.952218</td>\n      <td>115.244002</td>\n      <td>7.884160</td>\n      <td>0.331329</td>\n      <td>11.760232</td>\n      <td>0.476951</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.078000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>99.000000</td>\n      <td>62.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>27.300000</td>\n      <td>0.243750</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>117.000000</td>\n      <td>72.000000</td>\n      <td>23.000000</td>\n      <td>30.500000</td>\n      <td>32.000000</td>\n      <td>0.372500</td>\n      <td>29.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.000000</td>\n      <td>140.250000</td>\n      <td>80.000000</td>\n      <td>32.000000</td>\n      <td>127.250000</td>\n      <td>36.600000</td>\n      <td>0.626250</td>\n      <td>41.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>17.000000</td>\n      <td>199.000000</td>\n      <td>122.000000</td>\n      <td>99.000000</td>\n      <td>846.000000</td>\n      <td>67.100000</td>\n      <td>2.420000</td>\n      <td>81.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.describe()\n",
    "#weird that \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\" have zero values, imputate mean values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of 0 values:\n",
      "Glucose:  5\n",
      "BloodPressure:  35\n",
      "SkinThickness:  227\n",
      "Insulin:  374\n",
      "BMI:  11\n"
     ]
    }
   ],
   "source": [
    "print(\"Amount of 0 values:\")\n",
    "print(\"Glucose: \", len(original_df[original_df[\"Glucose\"] == 0]))\n",
    "print(\"BloodPressure: \", len(original_df[original_df[\"BloodPressure\"] == 0]))\n",
    "print(\"SkinThickness: \", len(original_df[original_df[\"SkinThickness\"] == 0]))\n",
    "print(\"Insulin: \", len(original_df[original_df[\"Insulin\"] == 0]))\n",
    "print(\"BMI: \", len(original_df[original_df[\"BMI\"] == 0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def imputation(data, columns):\n",
    "    for c in columns:\n",
    "         if c in data.columns:\n",
    "             data[c].replace(0, np.nan,inplace=True)\n",
    "             data[c].fillna(data[c].mean(), inplace=True)\n",
    "    return data\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\ncount   768.000000  768.000000     768.000000     768.000000  768.000000   \nmean      3.845052  121.686763      72.405184      29.153420  155.548223   \nstd       3.369578   30.435949      12.096346       8.790942   85.021108   \nmin       0.000000   44.000000      24.000000       7.000000   14.000000   \n25%       1.000000   99.750000      64.000000      25.000000  121.500000   \n50%       3.000000  117.000000      72.202592      29.153420  155.548223   \n75%       6.000000  140.250000      80.000000      32.000000  155.548223   \nmax      17.000000  199.000000     122.000000      99.000000  846.000000   \n\n              BMI  DiabetesPedigreeFunction         Age     Outcome  \ncount  768.000000                768.000000  768.000000  768.000000  \nmean    32.457464                  0.471876   33.240885    0.348958  \nstd      6.875151                  0.331329   11.760232    0.476951  \nmin     18.200000                  0.078000   21.000000    0.000000  \n25%     27.500000                  0.243750   24.000000    0.000000  \n50%     32.400000                  0.372500   29.000000    0.000000  \n75%     36.600000                  0.626250   41.000000    1.000000  \nmax     67.100000                  2.420000   81.000000    1.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n      <td>768.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.845052</td>\n      <td>121.686763</td>\n      <td>72.405184</td>\n      <td>29.153420</td>\n      <td>155.548223</td>\n      <td>32.457464</td>\n      <td>0.471876</td>\n      <td>33.240885</td>\n      <td>0.348958</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>3.369578</td>\n      <td>30.435949</td>\n      <td>12.096346</td>\n      <td>8.790942</td>\n      <td>85.021108</td>\n      <td>6.875151</td>\n      <td>0.331329</td>\n      <td>11.760232</td>\n      <td>0.476951</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>44.000000</td>\n      <td>24.000000</td>\n      <td>7.000000</td>\n      <td>14.000000</td>\n      <td>18.200000</td>\n      <td>0.078000</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.000000</td>\n      <td>99.750000</td>\n      <td>64.000000</td>\n      <td>25.000000</td>\n      <td>121.500000</td>\n      <td>27.500000</td>\n      <td>0.243750</td>\n      <td>24.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.000000</td>\n      <td>117.000000</td>\n      <td>72.202592</td>\n      <td>29.153420</td>\n      <td>155.548223</td>\n      <td>32.400000</td>\n      <td>0.372500</td>\n      <td>29.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>6.000000</td>\n      <td>140.250000</td>\n      <td>80.000000</td>\n      <td>32.000000</td>\n      <td>155.548223</td>\n      <td>36.600000</td>\n      <td>0.626250</td>\n      <td>41.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>17.000000</td>\n      <td>199.000000</td>\n      <td>122.000000</td>\n      <td>99.000000</td>\n      <td>846.000000</td>\n      <td>67.100000</td>\n      <td>2.420000</td>\n      <td>81.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = imputation(original_df, [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"])\n",
    "\n",
    "original_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_labels = original_df.Outcome.value_counts()\n",
    "x_labels = [0,1]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = total_labels.plot(kind='bar')\n",
    "ax.set_title('Class label distribution (Amount)')\n",
    "ax.set_xlabel('Labels')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_xticklabels(x_labels)\n",
    "\n",
    "rects = ax.patches\n",
    "\n",
    "for rect,lbl in zip(rects, total_labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height\n",
    "            , lbl, ha='center', va='bottom')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 864x576 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_labels = [0,1]\n",
    "total_labels_percentage = original_df.Outcome.value_counts()/len(original_df)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "ax = total_labels_percentage.plot(kind='bar')\n",
    "ax.set_title('Class label distribution (%)')\n",
    "ax.set_xlabel('Labels')\n",
    "ax.set_ylabel('Percentage')\n",
    "ax.set_xticklabels(x_labels)\n",
    "\n",
    "rects = ax.patches\n",
    "labels = []\n",
    "\n",
    "for lbl in total_labels_percentage:\n",
    "    labels.append(\"{0:.2f}\".format(lbl))\n",
    "\n",
    "for rect,lbl in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height\n",
    "            , lbl, ha='center', va='bottom')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "#we can now split attributes and class label\n",
    "X = original_df.drop('Outcome', axis=1)\n",
    "y = original_df.Outcome\n",
    "\n",
    "X.describe()\n",
    "\n",
    "#data_standardized used for SVC\n",
    "scaler = StandardScaler()\n",
    "data_standardized = scaler.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "X_training,X_testing,y_training,y_testing, = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED)\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_training, y_training, test_size=0.3, random_state=RANDOM_SEED)\n",
    "\n",
    "#standardized split for SVC\n",
    "X_training_svc,X_testing_svc,y_training_svc,y_testing_svc, = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED)\n",
    "x_train_svc, x_val_svc, y_train_svc, y_val_svc = train_test_split(X_training, y_training, test_size=0.3, random_state=RANDOM_SEED)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "#Methods for sampling\n",
    "ros = RandomOverSampler(random_state=RANDOM_SEED)\n",
    "rus = RandomUnderSampler(random_state=RANDOM_SEED)\n",
    "smote = SMOTE(random_state=RANDOM_SEED, sampling_strategy='minority')\n",
    "\n",
    "#Classifiers\n",
    "dtc = DecisionTreeClassifier(random_state=RANDOM_SEED)\n",
    "svc = SVC(random_state=RANDOM_SEED)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def smote_technique(X,y):\n",
    "    x_sample, y_sample = smote.fit_sample(X, y)\n",
    "    return x_sample,y_sample\n",
    "\n",
    "def random_oversampling_technique(X,y):\n",
    "    x_sample, y_sample = ros.fit_sample(x_train, y_train)\n",
    "    return x_sample,y_sample\n",
    "\n",
    "def random_undersampling_technique(X,y):\n",
    "    x_sample, y_sample = rus.fit_sample(x_train, y_train)\n",
    "    return x_sample,y_sample"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data balanced by Unbalanced Bagger\n",
      "\n",
      "Validation Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.77      0.76       102\n",
      "           1       0.59      0.55      0.57        60\n",
      "\n",
      "    accuracy                           0.69       162\n",
      "   macro avg       0.67      0.66      0.66       162\n",
      "weighted avg       0.69      0.69      0.69       162\n",
      "\n",
      "\n",
      "Validation Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       102\n",
      "           1       0.61      0.63      0.62        60\n",
      "\n",
      "    accuracy                           0.72       162\n",
      "   macro avg       0.70      0.70      0.70       162\n",
      "weighted avg       0.72      0.72      0.72       162\n",
      "\n",
      "\n",
      "Test Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       158\n",
      "           1       0.59      0.60      0.60        73\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.70      0.71      0.71       231\n",
      "weighted avg       0.75      0.74      0.75       231\n",
      "\n",
      "AUPRC:  0.48392690858444287\n",
      "AUC:  0.7064331541529391\n",
      "\n",
      "Test Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.83       158\n",
      "           1       0.62      0.63      0.63        73\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.72      0.73      0.73       231\n",
      "weighted avg       0.76      0.76      0.76       231\n",
      "\n",
      "AUPRC:  0.5085898921515359\n",
      "AUC:  0.726460898213976\n"
     ]
    }
   ],
   "source": [
    "#new method, using ros, rus and smote\n",
    "sampling_techniques = [ros, rus, smote]\n",
    "\n",
    "classifier_dtc = UnbalancedBagger.unbalanced_bagger(x_train, y_train, 10, sampling_techniques,base_estimator=dtc,random_seed=RANDOM_SEED)\n",
    "classifier_svc = UnbalancedBagger.unbalanced_bagger(x_train_svc, y_train_svc, 10, sampling_techniques,base_estimator=svc,random_seed=RANDOM_SEED)\n",
    "\n",
    "y_score_dtc = classifier_dtc(X_testing)\n",
    "y_score_svc = classifier_svc(X_testing_svc)\n",
    "\n",
    "print(\"Data balanced by Unbalanced Bagger\")\n",
    "print(\"\\nValidation Results (Decision Tree):\")\n",
    "print(classification_report(y_val, classifier_dtc(x_val)))\n",
    "print(\"\\nValidation Results (SVC):\")\n",
    "print(classification_report(y_val_svc, classifier_svc(x_val_svc)))\n",
    "\n",
    "print(\"\\nTest Results (Decision Tree):\")\n",
    "print(classification_report(y_testing, y_score_dtc))\n",
    "auprc_dtc = average_precision_score(y_testing,y_score_dtc)\n",
    "auc_dtc = roc_auc_score(y_testing,y_score_dtc)\n",
    "print(\"AUPRC: \", auprc_dtc)\n",
    "print(\"AUC: \", auc_dtc)\n",
    "print(\"\\nTest Results (SVC):\")\n",
    "print(classification_report(y_testing_svc, y_score_svc))\n",
    "auprc_svc = average_precision_score(y_testing,y_score_svc)\n",
    "auc_svc = roc_auc_score(y_testing,y_score_svc)\n",
    "print(\"AUPRC: \", auprc_svc)\n",
    "print(\"AUC: \", auc_svc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data balanced by Unbalanced Bagger (Only Oversampling)\n",
      "\n",
      "Validation Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73       102\n",
      "           1       0.53      0.52      0.53        60\n",
      "\n",
      "    accuracy                           0.65       162\n",
      "   macro avg       0.63      0.63      0.63       162\n",
      "weighted avg       0.65      0.65      0.65       162\n",
      "\n",
      "\n",
      "Validation Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.77      0.79       102\n",
      "           1       0.63      0.67      0.65        60\n",
      "\n",
      "    accuracy                           0.73       162\n",
      "   macro avg       0.72      0.72      0.72       162\n",
      "weighted avg       0.74      0.73      0.74       162\n",
      "\n",
      "\n",
      "Test Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       158\n",
      "           1       0.63      0.56      0.59        73\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.72      0.70      0.71       231\n",
      "weighted avg       0.75      0.76      0.75       231\n",
      "\n",
      "AUPRC:  0.49279578868619967\n",
      "AUC:  0.7048725507196116\n",
      "\n",
      "Test Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.83       158\n",
      "           1       0.63      0.71      0.67        73\n",
      "\n",
      "    accuracy                           0.78       231\n",
      "   macro avg       0.75      0.76      0.75       231\n",
      "weighted avg       0.79      0.78      0.78       231\n",
      "\n",
      "AUPRC:  0.5426297724994684\n",
      "AUC:  0.7612276747008844\n"
     ]
    }
   ],
   "source": [
    "#new method, using ros\n",
    "sampling_techniques = [ros]\n",
    "\n",
    "classifier_dtc = UnbalancedBagger.unbalanced_bagger(x_train, y_train, 10, sampling_techniques,base_estimator=dtc,random_seed=RANDOM_SEED)\n",
    "classifier_svc = UnbalancedBagger.unbalanced_bagger(x_train_svc, y_train_svc, 10, sampling_techniques,base_estimator=svc,random_seed=RANDOM_SEED)\n",
    "\n",
    "y_score_dtc = classifier_dtc(X_testing)\n",
    "y_score_svc = classifier_svc(X_testing_svc)\n",
    "\n",
    "print(\"Data balanced by Unbalanced Bagger (Only Oversampling)\")\n",
    "print(\"\\nValidation Results (Decision Tree):\")\n",
    "print(classification_report(y_val, classifier_dtc(x_val)))\n",
    "print(\"\\nValidation Results (SVC):\")\n",
    "print(classification_report(y_val_svc, classifier_svc(x_val_svc)))\n",
    "\n",
    "print(\"\\nTest Results (Decision Tree):\")\n",
    "print(classification_report(y_testing, y_score_dtc))\n",
    "auprc_dtc = average_precision_score(y_testing,y_score_dtc)\n",
    "auc_dtc = roc_auc_score(y_testing,y_score_dtc)\n",
    "print(\"AUPRC: \", auprc_dtc)\n",
    "print(\"AUC: \", auc_dtc)\n",
    "print(\"\\nTest Results (SVC):\")\n",
    "print(classification_report(y_testing_svc, y_score_svc))\n",
    "auprc_svc = average_precision_score(y_testing,y_score_svc)\n",
    "auc_svc = roc_auc_score(y_testing,y_score_svc)\n",
    "print(\"AUPRC: \", auprc_svc)\n",
    "print(\"AUC: \", auc_svc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data balanced by Unbalanced Bagger (Only Undersampling)\n",
      "\n",
      "Validation Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       102\n",
      "           1       0.58      0.57      0.57        60\n",
      "\n",
      "    accuracy                           0.69       162\n",
      "   macro avg       0.66      0.66      0.66       162\n",
      "weighted avg       0.68      0.69      0.68       162\n",
      "\n",
      "\n",
      "Validation Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77       102\n",
      "           1       0.61      0.60      0.61        60\n",
      "\n",
      "    accuracy                           0.71       162\n",
      "   macro avg       0.69      0.69      0.69       162\n",
      "weighted avg       0.71      0.71      0.71       162\n",
      "\n",
      "\n",
      "Test Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82       158\n",
      "           1       0.61      0.75      0.67        73\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.74      0.77      0.75       231\n",
      "weighted avg       0.79      0.77      0.78       231\n",
      "\n",
      "AUPRC:  0.5383482575263397\n",
      "AUC:  0.7659528350962372\n",
      "\n",
      "Test Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       158\n",
      "           1       0.65      0.66      0.65        73\n",
      "\n",
      "    accuracy                           0.78       231\n",
      "   macro avg       0.74      0.75      0.75       231\n",
      "weighted avg       0.78      0.78      0.78       231\n",
      "\n",
      "AUPRC:  0.5347338087064115\n",
      "AUC:  0.746488642275013\n"
     ]
    }
   ],
   "source": [
    "#new method, using rus\n",
    "sampling_techniques = [rus]\n",
    "\n",
    "classifier_dtc = UnbalancedBagger.unbalanced_bagger(x_train, y_train, 10, sampling_techniques,base_estimator=dtc,random_seed=RANDOM_SEED)\n",
    "classifier_svc = UnbalancedBagger.unbalanced_bagger(x_train_svc, y_train_svc, 10, sampling_techniques,base_estimator=svc,random_seed=RANDOM_SEED)\n",
    "\n",
    "y_score_dtc = classifier_dtc(X_testing)\n",
    "y_score_svc = classifier_svc(X_testing_svc)\n",
    "\n",
    "print(\"Data balanced by Unbalanced Bagger (Only Undersampling)\")\n",
    "print(\"\\nValidation Results (Decision Tree):\")\n",
    "print(classification_report(y_val, classifier_dtc(x_val)))\n",
    "print(\"\\nValidation Results (SVC):\")\n",
    "print(classification_report(y_val_svc, classifier_svc(x_val_svc)))\n",
    "\n",
    "print(\"\\nTest Results (Decision Tree):\")\n",
    "print(classification_report(y_testing, y_score_dtc))\n",
    "auprc_dtc = average_precision_score(y_testing,y_score_dtc)\n",
    "auc_dtc = roc_auc_score(y_testing,y_score_dtc)\n",
    "print(\"AUPRC: \", auprc_dtc)\n",
    "print(\"AUC: \", auc_dtc)\n",
    "print(\"\\nTest Results (SVC):\")\n",
    "print(classification_report(y_testing_svc, y_score_svc))\n",
    "auprc_svc = average_precision_score(y_testing,y_score_svc)\n",
    "auc_svc = roc_auc_score(y_testing,y_score_svc)\n",
    "print(\"AUPRC: \", auprc_svc)\n",
    "print(\"AUC: \", auc_svc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data balanced by Unbalanced Bagger (Only SMOTE)\n",
      "\n",
      "Validation Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.75       102\n",
      "           1       0.57      0.50      0.53        60\n",
      "\n",
      "    accuracy                           0.67       162\n",
      "   macro avg       0.65      0.64      0.64       162\n",
      "weighted avg       0.67      0.67      0.67       162\n",
      "\n",
      "\n",
      "Validation Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       102\n",
      "           1       0.67      0.68      0.68        60\n",
      "\n",
      "    accuracy                           0.76       162\n",
      "   macro avg       0.74      0.74      0.74       162\n",
      "weighted avg       0.76      0.76      0.76       162\n",
      "\n",
      "\n",
      "Test Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78       158\n",
      "           1       0.53      0.59      0.56        73\n",
      "\n",
      "    accuracy                           0.71       231\n",
      "   macro avg       0.67      0.67      0.67       231\n",
      "weighted avg       0.71      0.71      0.71       231\n",
      "\n",
      "AUPRC:  0.44257095855269374\n",
      "AUC:  0.6742673833882435\n",
      "\n",
      "Test Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       158\n",
      "           1       0.62      0.66      0.64        73\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.73      0.73      0.73       231\n",
      "weighted avg       0.77      0.76      0.76       231\n",
      "\n",
      "AUPRC:  0.5128615676560883\n",
      "AUC:  0.7338304144269118\n"
     ]
    }
   ],
   "source": [
    "#new method, using smote\n",
    "sampling_techniques = [smote]\n",
    "\n",
    "classifier_dtc = UnbalancedBagger.unbalanced_bagger(x_train, y_train, 10, sampling_techniques,base_estimator=dtc,random_seed=RANDOM_SEED)\n",
    "classifier_svc = UnbalancedBagger.unbalanced_bagger(x_train_svc, y_train_svc, 10, sampling_techniques,base_estimator=svc,random_seed=RANDOM_SEED)\n",
    "\n",
    "y_score_dtc = classifier_dtc(X_testing)\n",
    "y_score_svc = classifier_svc(X_testing_svc)\n",
    "\n",
    "print(\"Data balanced by Unbalanced Bagger (Only SMOTE)\")\n",
    "print(\"\\nValidation Results (Decision Tree):\")\n",
    "print(classification_report(y_val, classifier_dtc(x_val)))\n",
    "print(\"\\nValidation Results (SVC):\")\n",
    "print(classification_report(y_val_svc, classifier_svc(x_val_svc)))\n",
    "\n",
    "print(\"\\nTest Results (Decision Tree):\")\n",
    "print(classification_report(y_testing, y_score_dtc))\n",
    "auprc_dtc = average_precision_score(y_testing,y_score_dtc)\n",
    "auc_dtc = roc_auc_score(y_testing,y_score_dtc)\n",
    "print(\"AUPRC: \", auprc_dtc)\n",
    "print(\"AUC: \", auc_dtc)\n",
    "print(\"\\nTest Results (SVC):\")\n",
    "print(classification_report(y_testing_svc, y_score_svc))\n",
    "auprc_svc = average_precision_score(y_testing,y_score_svc)\n",
    "auc_svc = roc_auc_score(y_testing,y_score_svc)\n",
    "print(\"AUPRC: \", auprc_svc)\n",
    "print(\"AUC: \", auc_svc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data balanced by Unbalanced Bagger (Only SMOTE and Random Oversampling)\n",
      "\n",
      "Validation Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       102\n",
      "           1       0.58      0.55      0.56        60\n",
      "\n",
      "    accuracy                           0.69       162\n",
      "   macro avg       0.66      0.66      0.66       162\n",
      "weighted avg       0.68      0.69      0.68       162\n",
      "\n",
      "\n",
      "Validation Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78       102\n",
      "           1       0.64      0.58      0.61        60\n",
      "\n",
      "    accuracy                           0.72       162\n",
      "   macro avg       0.70      0.69      0.70       162\n",
      "weighted avg       0.72      0.72      0.72       162\n",
      "\n",
      "\n",
      "Test Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.81       158\n",
      "           1       0.59      0.58      0.58        73\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.70      0.70      0.70       231\n",
      "weighted avg       0.74      0.74      0.74       231\n",
      "\n",
      "AUPRC:  0.47454256464482203\n",
      "AUC:  0.6958990809779783\n",
      "\n",
      "Test Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       158\n",
      "           1       0.66      0.63      0.64        73\n",
      "\n",
      "    accuracy                           0.78       231\n",
      "   macro avg       0.74      0.74      0.74       231\n",
      "weighted avg       0.78      0.78      0.78       231\n",
      "\n",
      "AUPRC:  0.5309731364525885\n",
      "AUC:  0.7391191260620772\n"
     ]
    }
   ],
   "source": [
    "#new method, using smote and ros\n",
    "sampling_techniques = [smote, ros]\n",
    "\n",
    "classifier_dtc = UnbalancedBagger.unbalanced_bagger(x_train, y_train, 10, sampling_techniques,base_estimator=dtc,random_seed=RANDOM_SEED)\n",
    "classifier_svc = UnbalancedBagger.unbalanced_bagger(x_train_svc, y_train_svc, 10, sampling_techniques,base_estimator=svc,random_seed=RANDOM_SEED)\n",
    "\n",
    "y_score_dtc = classifier_dtc(X_testing)\n",
    "y_score_svc = classifier_svc(X_testing_svc)\n",
    "\n",
    "print(\"Data balanced by Unbalanced Bagger (Only SMOTE and Random Oversampling)\")\n",
    "print(\"\\nValidation Results (Decision Tree):\")\n",
    "print(classification_report(y_val, classifier_dtc(x_val)))\n",
    "print(\"\\nValidation Results (SVC):\")\n",
    "print(classification_report(y_val_svc, classifier_svc(x_val_svc)))\n",
    "\n",
    "print(\"\\nTest Results (Decision Tree):\")\n",
    "print(classification_report(y_testing, y_score_dtc))\n",
    "auprc_dtc = average_precision_score(y_testing,y_score_dtc)\n",
    "auc_dtc = roc_auc_score(y_testing,y_score_dtc)\n",
    "print(\"AUPRC: \", auprc_dtc)\n",
    "print(\"AUC: \", auc_dtc)\n",
    "print(\"\\nTest Results (SVC):\")\n",
    "print(classification_report(y_testing_svc, y_score_svc))\n",
    "auprc_svc = average_precision_score(y_testing,y_score_svc)\n",
    "auc_svc = roc_auc_score(y_testing,y_score_svc)\n",
    "print(\"AUPRC: \", auprc_svc)\n",
    "print(\"AUC: \", auc_svc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unbalanced_bagger_no_sampling\n",
      "\n",
      "Validation Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.77       102\n",
      "           1       0.61      0.47      0.53        60\n",
      "\n",
      "    accuracy                           0.69       162\n",
      "   macro avg       0.67      0.65      0.65       162\n",
      "weighted avg       0.68      0.69      0.68       162\n",
      "\n",
      "\n",
      "Validation Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       102\n",
      "           1       0.74      0.42      0.53        60\n",
      "\n",
      "    accuracy                           0.73       162\n",
      "   macro avg       0.73      0.66      0.67       162\n",
      "weighted avg       0.73      0.73      0.71       162\n",
      "\n",
      "\n",
      "Test Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81       158\n",
      "           1       0.59      0.62      0.60        73\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.71      0.71      0.71       231\n",
      "weighted avg       0.75      0.74      0.75       231\n",
      "\n",
      "AUPRC:  0.48620851630945355\n",
      "AUC:  0.710117912259407\n",
      "\n",
      "Test Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86       158\n",
      "           1       0.85      0.40      0.54        73\n",
      "\n",
      "    accuracy                           0.79       231\n",
      "   macro avg       0.81      0.68      0.70       231\n",
      "weighted avg       0.80      0.79      0.76       231\n",
      "\n",
      "AUPRC:  0.5293158359234105\n",
      "AUC:  0.6828073521761748\n"
     ]
    }
   ],
   "source": [
    "classifier_dtc = UnbalancedBaggerNoSampling.unbalanced_bagger_no_sampling(x_train, y_train, 10,base_estimator=dtc,random_seed=RANDOM_SEED)\n",
    "classifier_svc = UnbalancedBaggerNoSampling.unbalanced_bagger_no_sampling(x_train_svc, y_train_svc, 10,base_estimator=svc,random_seed=RANDOM_SEED)\n",
    "y_score_dtc = classifier_dtc(X_testing)\n",
    "y_score_svc = classifier_svc(X_testing_svc)\n",
    "\n",
    "print(\"unbalanced_bagger_no_sampling\")\n",
    "print(\"\\nValidation Results (Decision Tree):\")\n",
    "print(classification_report(y_val, classifier_dtc(x_val)))\n",
    "print(\"\\nValidation Results (SVC):\")\n",
    "print(classification_report(y_val_svc, classifier_svc(x_val_svc)))\n",
    "\n",
    "print(\"\\nTest Results (Decision Tree):\")\n",
    "print(classification_report(y_testing, y_score_dtc))\n",
    "auprc_dtc = average_precision_score(y_testing,y_score_dtc)\n",
    "auc_dtc = roc_auc_score(y_testing,y_score_dtc)\n",
    "print(\"AUPRC: \", auprc_dtc)\n",
    "print(\"AUC: \", auc_dtc)\n",
    "print(\"\\nTest Results (SVC):\")\n",
    "print(classification_report(y_testing_svc, y_score_svc))\n",
    "auprc_svc = average_precision_score(y_testing,y_score_svc)\n",
    "auc_svc = roc_auc_score(y_testing,y_score_svc)\n",
    "print(\"AUPRC: \", auprc_svc)\n",
    "print(\"AUC: \", auc_svc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data\n",
      "\n",
      "Validation Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       102\n",
      "           1       0.54      0.50      0.52        60\n",
      "\n",
      "    accuracy                           0.65       162\n",
      "   macro avg       0.63      0.62      0.62       162\n",
      "weighted avg       0.65      0.65      0.65       162\n",
      "\n",
      "\n",
      "Validation Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81       102\n",
      "           1       0.74      0.43      0.55        60\n",
      "\n",
      "    accuracy                           0.73       162\n",
      "   macro avg       0.74      0.67      0.68       162\n",
      "weighted avg       0.74      0.73      0.71       162\n",
      "\n",
      "\n",
      "Test Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80       158\n",
      "           1       0.58      0.62      0.60        73\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.70      0.70      0.70       231\n",
      "weighted avg       0.74      0.74      0.74       231\n",
      "\n",
      "AUPRC:  0.47684963438388095\n",
      "AUC:  0.7037887983353563\n",
      "\n",
      "Test Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.87       158\n",
      "           1       0.87      0.47      0.61        73\n",
      "\n",
      "    accuracy                           0.81       231\n",
      "   macro avg       0.83      0.72      0.74       231\n",
      "weighted avg       0.82      0.81      0.79       231\n",
      "\n",
      "AUPRC:  0.5748726159685064\n",
      "AUC:  0.7170539275186406\n"
     ]
    }
   ],
   "source": [
    "#Train on original data\n",
    "print(\"Original data\")\n",
    "dtc.fit(x_train, y_train)\n",
    "svc.fit(x_train_svc,y_train_svc)\n",
    "\n",
    "print(\"\\nValidation Results (Decision Tree):\")\n",
    "print(classification_report(y_val, dtc.predict(x_val)))\n",
    "print(\"\\nValidation Results (SVC):\")\n",
    "print(classification_report(y_val_svc, svc.predict(x_val_svc)))\n",
    "\n",
    "print(\"\\nTest Results (Decision Tree):\")\n",
    "print(classification_report(y_testing, dtc.predict(X_testing)))\n",
    "auprc_dtc = average_precision_score(y_testing,dtc.predict(X_testing))\n",
    "auc_dtc = roc_auc_score(y_testing,dtc.predict(X_testing))\n",
    "print(\"AUPRC: \", auprc_dtc)\n",
    "print(\"AUC: \", auc_dtc)\n",
    "print(\"\\nTest Results (SVC):\")\n",
    "print(classification_report(y_testing_svc, svc.predict(X_testing_svc)))\n",
    "auprc_svc = average_precision_score(y_testing,svc.predict(X_testing))\n",
    "auc_svc = roc_auc_score(y_testing,svc.predict(X_testing))\n",
    "print(\"AUPRC: \", auprc_svc)\n",
    "print(\"AUC: \", auc_svc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data balanced by SMOTE\n",
      "\n",
      "Validation Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.77      0.75       102\n",
      "           1       0.57      0.50      0.53        60\n",
      "\n",
      "    accuracy                           0.67       162\n",
      "   macro avg       0.65      0.64      0.64       162\n",
      "weighted avg       0.67      0.67      0.67       162\n",
      "\n",
      "\n",
      "Validation Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.79      0.78       102\n",
      "           1       0.62      0.58      0.60        60\n",
      "\n",
      "    accuracy                           0.72       162\n",
      "   macro avg       0.69      0.69      0.69       162\n",
      "weighted avg       0.71      0.72      0.71       162\n",
      "\n",
      "\n",
      "Test Results (Decision Tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.81      0.81       158\n",
      "           1       0.59      0.60      0.60        73\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.70      0.71      0.71       231\n",
      "weighted avg       0.75      0.74      0.75       231\n",
      "\n",
      "AUPRC:  0.48392690858444287\n",
      "AUC:  0.7064331541529391\n",
      "\n",
      "Test Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       158\n",
      "           1       0.62      0.66      0.64        73\n",
      "\n",
      "    accuracy                           0.76       231\n",
      "   macro avg       0.73      0.73      0.73       231\n",
      "weighted avg       0.77      0.76      0.76       231\n",
      "\n",
      "AUPRC:  0.5128615676560883\n",
      "AUC:  0.7338304144269118\n"
     ]
    }
   ],
   "source": [
    "#Train on SMOTE\n",
    "sampled_dtc_x, sampled_dtc_y = smote_technique(x_train,y_train)\n",
    "sampled_svc_x, sampled_svc_y = smote_technique(x_train_svc,y_train_svc)\n",
    "\n",
    "dtc.fit(sampled_dtc_x,sampled_dtc_y)\n",
    "svc.fit(sampled_svc_x,sampled_svc_y)\n",
    "\n",
    "print(\"Data balanced by SMOTE\")\n",
    "print(\"\\nValidation Results (Decision Tree):\")\n",
    "print(classification_report(y_val, dtc.predict(x_val)))\n",
    "print(\"\\nValidation Results (SVC):\")\n",
    "print(classification_report(y_val, svc.predict(x_val_svc)))\n",
    "\n",
    "print(\"\\nTest Results (Decision Tree):\")\n",
    "print(classification_report(y_testing, dtc.predict(X_testing)))\n",
    "auprc_dtc = average_precision_score(y_testing,dtc.predict(X_testing))\n",
    "auc_dtc = roc_auc_score(y_testing,dtc.predict(X_testing))\n",
    "print(\"AUPRC: \", auprc_dtc)\n",
    "print(\"AUC: \", auc_dtc)\n",
    "print(\"\\nTest Results (SVC):\")\n",
    "print(classification_report(y_testing, svc.predict(X_testing_svc)))\n",
    "auprc_svc = average_precision_score(y_testing,svc.predict(X_testing))\n",
    "auc_svc = roc_auc_score(y_testing,svc.predict(X_testing))\n",
    "print(\"AUPRC: \", auprc_svc)\n",
    "print(\"AUC: \", auc_svc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data balanced by Random Oversampling\n",
      "\n",
      "Validation Results (Decision tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       102\n",
      "           1       0.65      0.52      0.57        60\n",
      "\n",
      "    accuracy                           0.72       162\n",
      "   macro avg       0.70      0.68      0.68       162\n",
      "weighted avg       0.71      0.72      0.71       162\n",
      "\n",
      "\n",
      "Validation Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78       102\n",
      "           1       0.64      0.58      0.61        60\n",
      "\n",
      "    accuracy                           0.72       162\n",
      "   macro avg       0.70      0.69      0.70       162\n",
      "weighted avg       0.72      0.72      0.72       162\n",
      "\n",
      "\n",
      "Test Results (Decision tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       158\n",
      "           1       0.58      0.60      0.59        73\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.70      0.70      0.70       231\n",
      "weighted avg       0.74      0.74      0.74       231\n",
      "\n",
      "AUPRC:  0.47449570376751343\n",
      "AUC:  0.7001040402288885\n",
      "\n",
      "Test Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       158\n",
      "           1       0.63      0.66      0.64        73\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.74      0.74      0.74       231\n",
      "weighted avg       0.77      0.77      0.77       231\n",
      "\n",
      "AUPRC:  0.5235098955358508\n",
      "AUC:  0.7401595283509622\n"
     ]
    }
   ],
   "source": [
    "#Train on Random Oversampling\n",
    "sampled_dtc_x, sampled_dtc_y = random_oversampling_technique(x_train,y_train)\n",
    "sampled_svc_x, sampled_svc_y = random_oversampling_technique(x_train_svc,y_train_svc)\n",
    "\n",
    "dtc.fit(sampled_dtc_x,sampled_dtc_y)\n",
    "svc.fit(sampled_svc_x,sampled_svc_y)\n",
    "\n",
    "print(\"Data balanced by Random Oversampling\")\n",
    "print(\"\\nValidation Results (Decision tree):\")\n",
    "print(classification_report(y_val, dtc.predict(x_val)))\n",
    "print(\"\\nValidation Results (SVC):\")\n",
    "print(classification_report(y_val, svc.predict(x_val_svc)))\n",
    "\n",
    "print(\"\\nTest Results (Decision tree):\")\n",
    "print(classification_report(y_testing, dtc.predict(X_testing)))\n",
    "auprc_dtc = average_precision_score(y_testing,dtc.predict(X_testing))\n",
    "auc_dtc = roc_auc_score(y_testing,dtc.predict(X_testing))\n",
    "print(\"AUPRC: \", auprc_dtc)\n",
    "print(\"AUC: \", auc_dtc)\n",
    "print(\"\\nTest Results (SVC):\")\n",
    "print(classification_report(y_testing, svc.predict(X_testing_svc)))\n",
    "auprc_svc = average_precision_score(y_testing,svc.predict(X_testing))\n",
    "auc_svc = roc_auc_score(y_testing,svc.predict(X_testing))\n",
    "print(\"AUPRC: \", auprc_svc)\n",
    "print(\"AUC: \", auc_svc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data balanced by Random Undersampling\n",
      "\n",
      "Validation Results (Decision tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70       102\n",
      "           1       0.50      0.52      0.51        60\n",
      "\n",
      "    accuracy                           0.63       162\n",
      "   macro avg       0.60      0.61      0.61       162\n",
      "weighted avg       0.63      0.63      0.63       162\n",
      "\n",
      "\n",
      "Validation Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75       102\n",
      "           1       0.57      0.58      0.58        60\n",
      "\n",
      "    accuracy                           0.69       162\n",
      "   macro avg       0.66      0.66      0.66       162\n",
      "weighted avg       0.69      0.69      0.69       162\n",
      "\n",
      "\n",
      "Test Results (Decision tree):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.70      0.76       158\n",
      "           1       0.52      0.68      0.59        73\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.67      0.69      0.67       231\n",
      "weighted avg       0.73      0.70      0.71       231\n",
      "\n",
      "AUPRC:  0.47449570376751343\n",
      "AUC:  0.6937315762094677\n",
      "\n",
      "Test Results (SVC):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.82       158\n",
      "           1       0.60      0.64      0.62        73\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.72      0.72      0.72       231\n",
      "weighted avg       0.76      0.75      0.76       231\n",
      "\n",
      "AUPRC:  0.5005063429720964\n",
      "AUC:  0.7238165423963934\n"
     ]
    }
   ],
   "source": [
    "#Train on Random Undersampling\n",
    "sampled_dtc_x, sampled_dtc_y = random_undersampling_technique(x_train,y_train)\n",
    "sampled_svc_x, sampled_svc_y = random_undersampling_technique(x_train_svc,y_train_svc)\n",
    "\n",
    "dtc.fit(sampled_dtc_x,sampled_dtc_y)\n",
    "svc.fit(sampled_svc_x,sampled_svc_y)\n",
    "\n",
    "print(\"Data balanced by Random Undersampling\")\n",
    "print(\"\\nValidation Results (Decision tree):\")\n",
    "print(classification_report(y_val, dtc.predict(x_val)))\n",
    "print(\"\\nValidation Results (SVC):\")\n",
    "print(classification_report(y_val, svc.predict(x_val_svc)))\n",
    "\n",
    "print(\"\\nTest Results (Decision tree):\")\n",
    "print(classification_report(y_testing, dtc.predict(X_testing)))\n",
    "auc_dtc = roc_auc_score(y_testing,dtc.predict(X_testing))\n",
    "print(\"AUPRC: \", auprc_dtc)\n",
    "print(\"AUC: \", auc_dtc)\n",
    "print(\"\\nTest Results (SVC):\")\n",
    "print(classification_report(y_testing, svc.predict(X_testing_svc)))\n",
    "auprc_svc = average_precision_score(y_testing,svc.predict(X_testing))\n",
    "auc_svc = roc_auc_score(y_testing,svc.predict(X_testing))\n",
    "print(\"AUPRC: \", auprc_svc)\n",
    "print(\"AUC: \", auc_svc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "DAMI2 Project Report Code - Handling unbalanced datasets\n",
     "\n",
     "2020 Jimmy Ljungman\n",
     "\n",
     "This code imports a data set, preprocesses it, run a new sampling technique\n",
     "called 'Unbalanced_bagging' and measure its performance against other sampling techniques\n",
     "such as random oversampling and random undersampling.\n",
     "\n",
     "Unbalanced_bagging will be measured against the other techniques using the metrics AUPRC and time complexity.\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}